{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training using cuda\n"
     ]
    }
   ],
   "source": [
    "# Training settings\n",
    "bs = 64\n",
    "lr = 0.001\n",
    "num_epoch = 5\n",
    "num_classes = 10\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Training using ' + device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "mnist_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data/mnist/', train=True,\n",
    "                                          download=False,\n",
    "                                          transform=mnist_transforms)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data/mnist', train=False,\n",
    "                                         download=False,\n",
    "                                         transform=mnist_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=bs, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(Model, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Linear(7*7*32, num_classes)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "    \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of Model(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc): Linear(in_features=1568, out_features=10, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(num_classes).to(device)\n",
    "\n",
    "# Optimzer and loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def train(num_epochs=5):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for idx, (images, labels) in enumerate(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward and Update weights\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Print the loss\n",
    "            if (idx) % bs-1 == 0:\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}] | Batch [{idx*len(images)}/{len(train_loader.dataset)}] | Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        test_loss = 0\n",
    "        \n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            out = model(images)\n",
    "            # total loss\n",
    "            test_loss += criterion(out, labels)\n",
    "            # get the index of the max value, calculate how many accurate predictions\n",
    "            pred = out.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(labels.data.view_as(pred)).cpu().sum()\n",
    "            \n",
    "        # Average loss for the whole test 10000 images    \n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        print(\"==========================\")\n",
    "        print(f\"Test set: Average Loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)}, {100*correct/len(test_loader.dataset):.0f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run() aka main\n",
    "def run():\n",
    "    # Training\n",
    "    train_time = time.time()\n",
    "    train(num_epoch)\n",
    "    m, s = divmod(time.time() - train_time, 60)\n",
    "    print(f'Training Time: {m:.0f}m {s:.0f}s')\n",
    "    # Testing\n",
    "    test_time = time.time()\n",
    "    test()\n",
    "    m, s = divmod(time.time() - test_time, 60)\n",
    "    print(f'Testing Time: {m:.0f}m {s:.0f}s')\n",
    "    # Total\n",
    "    m, s = divmod(time.time() - train_time, 60)\n",
    "    print(f'Total Time: {m:.0f}m {s:.0f}s\\nTrained on {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] | Batch [64/60000] | Loss: 0.0006\n",
      "Epoch [1/5] | Batch [4160/60000] | Loss: 0.0004\n",
      "Epoch [1/5] | Batch [8256/60000] | Loss: 0.0019\n",
      "Epoch [1/5] | Batch [12352/60000] | Loss: 0.0002\n",
      "Epoch [1/5] | Batch [16448/60000] | Loss: 0.0007\n",
      "Epoch [1/5] | Batch [20544/60000] | Loss: 0.0002\n",
      "Epoch [1/5] | Batch [24640/60000] | Loss: 0.0001\n",
      "Epoch [1/5] | Batch [28736/60000] | Loss: 0.0000\n",
      "Epoch [1/5] | Batch [32832/60000] | Loss: 0.0006\n",
      "Epoch [1/5] | Batch [36928/60000] | Loss: 0.0118\n",
      "Epoch [1/5] | Batch [41024/60000] | Loss: 0.0162\n",
      "Epoch [1/5] | Batch [45120/60000] | Loss: 0.0115\n",
      "Epoch [1/5] | Batch [49216/60000] | Loss: 0.0373\n",
      "Epoch [1/5] | Batch [53312/60000] | Loss: 0.0101\n",
      "Epoch [1/5] | Batch [57408/60000] | Loss: 0.0001\n",
      "Epoch [2/5] | Batch [64/60000] | Loss: 0.0004\n",
      "Epoch [2/5] | Batch [4160/60000] | Loss: 0.0000\n",
      "Epoch [2/5] | Batch [8256/60000] | Loss: 0.0002\n",
      "Epoch [2/5] | Batch [12352/60000] | Loss: 0.0007\n",
      "Epoch [2/5] | Batch [16448/60000] | Loss: 0.0003\n",
      "Epoch [2/5] | Batch [20544/60000] | Loss: 0.0002\n",
      "Epoch [2/5] | Batch [24640/60000] | Loss: 0.0001\n",
      "Epoch [2/5] | Batch [28736/60000] | Loss: 0.0012\n",
      "Epoch [2/5] | Batch [32832/60000] | Loss: 0.0123\n",
      "Epoch [2/5] | Batch [36928/60000] | Loss: 0.0002\n",
      "Epoch [2/5] | Batch [41024/60000] | Loss: 0.0402\n",
      "Epoch [2/5] | Batch [45120/60000] | Loss: 0.0005\n",
      "Epoch [2/5] | Batch [49216/60000] | Loss: 0.0497\n",
      "Epoch [2/5] | Batch [53312/60000] | Loss: 0.0004\n",
      "Epoch [2/5] | Batch [57408/60000] | Loss: 0.0005\n",
      "Epoch [3/5] | Batch [64/60000] | Loss: 0.0009\n",
      "Epoch [3/5] | Batch [4160/60000] | Loss: 0.0004\n",
      "Epoch [3/5] | Batch [8256/60000] | Loss: 0.0031\n",
      "Epoch [3/5] | Batch [12352/60000] | Loss: 0.0029\n",
      "Epoch [3/5] | Batch [16448/60000] | Loss: 0.0002\n",
      "Epoch [3/5] | Batch [20544/60000] | Loss: 0.0005\n",
      "Epoch [3/5] | Batch [24640/60000] | Loss: 0.0003\n",
      "Epoch [3/5] | Batch [28736/60000] | Loss: 0.0001\n",
      "Epoch [3/5] | Batch [32832/60000] | Loss: 0.0022\n",
      "Epoch [3/5] | Batch [36928/60000] | Loss: 0.0375\n",
      "Epoch [3/5] | Batch [41024/60000] | Loss: 0.0022\n",
      "Epoch [3/5] | Batch [45120/60000] | Loss: 0.0005\n",
      "Epoch [3/5] | Batch [49216/60000] | Loss: 0.0414\n",
      "Epoch [3/5] | Batch [53312/60000] | Loss: 0.0004\n",
      "Epoch [3/5] | Batch [57408/60000] | Loss: 0.0007\n",
      "Epoch [4/5] | Batch [64/60000] | Loss: 0.0049\n",
      "Epoch [4/5] | Batch [4160/60000] | Loss: 0.0000\n",
      "Epoch [4/5] | Batch [8256/60000] | Loss: 0.0003\n",
      "Epoch [4/5] | Batch [12352/60000] | Loss: 0.0001\n",
      "Epoch [4/5] | Batch [16448/60000] | Loss: 0.0008\n",
      "Epoch [4/5] | Batch [20544/60000] | Loss: 0.0008\n",
      "Epoch [4/5] | Batch [24640/60000] | Loss: 0.0000\n",
      "Epoch [4/5] | Batch [28736/60000] | Loss: 0.0008\n",
      "Epoch [4/5] | Batch [32832/60000] | Loss: 0.0005\n",
      "Epoch [4/5] | Batch [36928/60000] | Loss: 0.0032\n",
      "Epoch [4/5] | Batch [41024/60000] | Loss: 0.0001\n",
      "Epoch [4/5] | Batch [45120/60000] | Loss: 0.0001\n",
      "Epoch [4/5] | Batch [49216/60000] | Loss: 0.0441\n",
      "Epoch [4/5] | Batch [53312/60000] | Loss: 0.0083\n",
      "Epoch [4/5] | Batch [57408/60000] | Loss: 0.0019\n",
      "Epoch [5/5] | Batch [64/60000] | Loss: 0.0002\n",
      "Epoch [5/5] | Batch [4160/60000] | Loss: 0.0002\n",
      "Epoch [5/5] | Batch [8256/60000] | Loss: 0.0001\n",
      "Epoch [5/5] | Batch [12352/60000] | Loss: 0.0006\n",
      "Epoch [5/5] | Batch [16448/60000] | Loss: 0.0002\n",
      "Epoch [5/5] | Batch [20544/60000] | Loss: 0.0001\n",
      "Epoch [5/5] | Batch [24640/60000] | Loss: 0.0004\n",
      "Epoch [5/5] | Batch [28736/60000] | Loss: 0.0000\n",
      "Epoch [5/5] | Batch [32832/60000] | Loss: 0.0024\n",
      "Epoch [5/5] | Batch [36928/60000] | Loss: 0.0083\n",
      "Epoch [5/5] | Batch [41024/60000] | Loss: 0.0000\n",
      "Epoch [5/5] | Batch [45120/60000] | Loss: 0.0000\n",
      "Epoch [5/5] | Batch [49216/60000] | Loss: 0.0000\n",
      "Epoch [5/5] | Batch [53312/60000] | Loss: 0.0000\n",
      "Epoch [5/5] | Batch [57408/60000] | Loss: 0.0013\n",
      "Training Time: 0m 45s\n",
      "==========================\n",
      "Test set: Average Loss: 0.0005, Accuracy: 9908/10000, 99%\n",
      "Testing Time: 0m 1s\n",
      "Total Time: 0m 46s\n",
      "Trained on cuda\n"
     ]
    }
   ],
   "source": [
    "run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
